# container serving a LLM locally
Basic API serving 'small llm' (slm?)
Plan is to use https://huggingface.co/distilbert/distilgpt2  (License Apache 2)

